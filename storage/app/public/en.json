{
    "trans.Register": "Register",
    "trans.Name": "Name",
    "trans.code.used": "This Code Snippet is used in program no. :id with name:",
    "trans.Email Address": "Email Address",
    "trans.Code deleted permanently":  "Code deleted permanently",
    "trans.Code created successfully": "Code created successfully",
    "trans.Password": "Password",
    "trans.Confirm Password": "Confirm Password",
    "trans.Login": "Login",
    "trans.Logout": "Logout",
    "trans.The provided credentials do not match our records.": "The provided credentials do not match our records.",
    "trans.You have successfully registered!": "You have successfully registered!",
    "trans.Create Code": "Create Code",
    "trans.Create row category": "Create row category",
    "trans.My codes": "My codes",
    "trans.My archive": "My archive",
    "trans.Approve codes": "Approve codes",
    "trans.Business Understanding": "Business understanding",
    "trans.Data Understanding": "Data understanding",
    "trans.Data preparation": "Data preparation",
    "trans.Modeling": "Modeling",
    "trans.Evaluation": "Evaluation",
    "trans.Deployment": "Deployment",
    "trans.Unknown crispdm": "Unknown CRISP-DM",
    "trans.Neural Network": "Neural Network",
    "trans.Natural Language Processing": "Natural Language Processing",
    "trans.Machine Learning": "Machine Learning",
    "trans.Unknown type": "Unknown type",
    "trans.home.welcome": "Welcome to CodeSnippets! Here you can search for various codes and Code Snippets filtered by categories and CRISP-DM methodology. As a user, you can only search these codes. After registration, you can add your own categories and upload your personal codes and Code Snippets to help others too.",
    "trans.Scroll to the top": "Scroll to the top",
    "trans.Code name": "Code name",
    "trans.Code description": "Code description",
    "trans.Code category": "Code category",
    "trans.Description": "Description",
    "trans.Code": "Code",
    "trans.Row category": "Row category",
    "trans.Code updated successfully": "Code updated successfully",
    "trans.Snippet deleted successfully": "Snippet deleted successfully",
    "trans.Add new snippet": "Add new snippet",
    "trans.Code archived successfully": "Code archived successfully",
    "trans.Code restored successfully": "Code restored successfully",
    "trans.Code cant restored": "Code cant restored",
    "trans.Code approved successfully": "Code approved successfully",
    "trans.Submit": "Submit",
    "trans.Approve": "Approve",
    "trans.Delete": "Delete",
    "trans.Archive": "Archive",
    "trans.Edit": "Edit",
    "trans.Save": "Save",
    "trans.row.category.1": "Importing Required Libraries",
    "trans.row.category.2": "Loading Data",
    "trans.row.category.3": "Data Visualization",
    "trans.row.category.4": "Data Preprocessing",
    "trans.row.category.5": "Feature Selection",
    "trans.row.category.6": "Splitting Data",
    "trans.row.category.7": "Building Decision Tree Model",
    "trans.row.category.8": "Model Training",
    "trans.row.category.9": "Model Prediction",
    "trans.row.category.10": "Evaluating the Model",
    "trans.row.category.11": "Visualizing Decision Trees",
    "trans.row.category.12": "Data Analysis",
    "trans.row.category.13": "Model Interpretation",
    "trans.row.category.14": "Advanced Visualization",
    "trans.row.category.15": "Handling Missing Data",
    "trans.row.category.16": "Data Exploration",
    "trans.row.category.17": "Feature Engineering",
    "trans.row.category.18": "Model Optimization",
    "trans.row.category.19": "Neural Network Setup",
    "trans.row.category.20": "Text Processing",
    "trans.row.category.21": "Web Scraping",
    "trans.row.category.22": "Image Processing",
    "trans.You don't have any code yet": "You don't have any code yet",
    "trans.Click here to create a new code": "Click here to create a new code",
    "trans.No codes need approval": "No codes need approval",
    "trans.Row category in English:": "Row category in English:",
    "trans.Row category in Slovak:": "Row category in Slovak:",
    "trans.Please enter a value": "Please enter a value",
    "trans.Row category created successfully": "Row category created successfully",
    "trans.Filters": "Filters",
    "trans.Create new code": "Create new code",
    "trans.Approved": "Approved",
    "trans.Not approved yet": "Not approved yet",
    "trans.Editing": "Editing",
    "trans.Select snippet categories": "Select snippet categories",
    "trans.Select crispdm": "Select CRISP-DM",
    "trans.Select code categories": "Select code categories",
    "trans.Search in desc and code": "Search in description and code",
    "trans.Copy to clipboard": "Copy to clipboard",
    "trans.Show code": "Show code",
    "trans.Connected codes": "Connected codes",
    "trans.Restore": "Restore",
    "trans.Hi": "Hi",
    "trans.snippet.description.1": "Importing Pandas library",
    "trans.snippet.description.2": "Loading dataset",
    "trans.snippet.description.3": "Displaying dataset",
    "trans.snippet.description.4": "Displaying first rows of dataset",
    "trans.snippet.description.5": "Encoding categories",
    "trans.snippet.description.6": "Encoding additional categories",
    "trans.snippet.description.7": "Importing train_test_split library",
    "trans.snippet.description.8": "Separating input features (X) from target variable (y)",
    "trans.snippet.description.9": "Splitting data into training and test sets",
    "trans.snippet.description.10": "Displaying training data",
    "trans.snippet.description.11": "Displaying test data",
    "trans.snippet.description.12": "Importing DecisionTreeClassifier library",
    "trans.snippet.description.13": "Training decision tree",
    "trans.snippet.description.14": "Training decision tree on training data",
    "trans.snippet.description.15": "Predicting values on test data",
    "trans.snippet.description.16": "Importing metrics library",
    "trans.snippet.description.17": "Evaluating model accuracy",
    "trans.snippet.description.18": "Getting list of features",
    "trans.snippet.description.19": "Importing matplotlib library",
    "trans.snippet.description.20": "Importing tree library",
    "trans.snippet.description.21": "Plotting decision tree",
    "trans.snippet.description.22": "Displaying extracted features",
    "trans.snippet.description.23": "Re-plotting decision tree",
    "trans.snippet.description.24": "Loading dataset",
    "trans.snippet.description.25": "Displaying dataset",
    "trans.snippet.description.26": "Displaying basic statistical values of dataset",
    "trans.snippet.description.27": "Importing Counter library",
    "trans.snippet.description.28": "Counting value frequency of attribute",
    "trans.snippet.description.29": "Selecting all dataset features except target variable, defining target variable",
    "trans.snippet.description.30": "Creating decision tree model with gini criterion",
    "trans.snippet.description.31": "Importing confusion_matrix library",
    "trans.snippet.description.32": "Creating confusion matrix to analyze correct/incorrect predictions",
    "trans.snippet.description.33": "Loading dataset",
    "trans.snippet.description.34": "Displaying dataset",
    "trans.snippet.description.35": "Encoding gender",
    "trans.snippet.description.36": "Splitting data into training/test sets",
    "trans.snippet.description.37": "Displaying maximum depth of trained decision tree",
    "trans.snippet.description.38": "Displaying total number of leaves in trained decision tree",
    "trans.snippet.description.39": "Creating decision tree model with entropy criterion",
    "trans.snippet.description.40": "Training models and analyzing accuracy based on decision tree depth",
    "trans.snippet.description.41": "Displaying list of accuracies for gini criterion decision tree",
    "trans.snippet.description.42": "Displaying list of accuracies for entropy criterion decision tree",
    "trans.snippet.description.43": "Importing export_graphviz library",
    "trans.snippet.description.44": "Importing StringIO library",
    "trans.snippet.description.45": "Importing Image library",
    "trans.snippet.description.46": "Importing pydotplus library",
    "trans.snippet.description.47": "Creating DataFrame containing decision trees' accuracies",
    "trans.snippet.description.48": "Plotting decision trees' accuracy changes based on max depth",
    "trans.snippet.description.49": "Training models and analyzing accuracy based on decision tree depth (gini)",
    "trans.snippet.description.50": "Creating pandas DataFrame with training/test data accuracy",
    "trans.snippet.description.51": "Plotting training/test data accuracy",
    "trans.snippet.description.52": "Creating decision tree model with fixed random_state parameter",
    "trans.snippet.description.53": "Calculating decision tree pruning path based on training data",
    "trans.snippet.description.54": "Extracting ccp_alphas and impurities from pruning path",
    "trans.snippet.description.55": "Plotting graph showing total leaf impurity",
    "trans.snippet.description.56": "Importing NumPy library",
    "trans.snippet.description.57": "Importing Seaborn library",
    "trans.snippet.description.58": "Displaying first 5 dataset rows for quick overview",
    "trans.snippet.description.59": "Listing all parameters of trained decision tree",
    "trans.snippet.description.60": "Defining test vector representing individual with various attributes",
    "trans.snippet.description.61": "Printing contents of 'person' variable",
    "trans.snippet.description.62": "Reshaping input data to 2D array for model compatibility",
    "trans.snippet.description.63": "Using decision tree model to predict for 'person'",
    "trans.snippet.description.64": "Displaying decision path taken for 'person' prediction",
    "trans.snippet.description.65": "Loading Possum dataset",
    "trans.snippet.description.66": "Displaying first 5 rows of dataset",
    "trans.snippet.description.67": "Printing basic dataset info",
    "trans.snippet.description.68": "Selecting all features except target (age), defining target variable",
    "trans.snippet.description.69": "Splitting data into 70:30 train/test ratio",
    "trans.snippet.description.70": "Importing DecisionTreeRegressor for regression prediction",
    "trans.snippet.description.71": "Converting 'other' and 'Vic' text values to 0 and 1",
    "trans.snippet.description.72": "Converting 'm' and 'f' text values to 0 and 1",
    "trans.snippet.description.73": "Counting occurrences in 'Pop' attribute",
    "trans.snippet.description.74": "Counting occurrences in 'sex' attribute",
    "trans.snippet.description.75": "Removing rows with missing values",
    "trans.snippet.description.76": "Creating DecisionTreeRegressor instance with default parameters",
    "trans.snippet.description.77": "Training model using training data (X_train, y_train)",
    "trans.snippet.description.78": "Using model to predict test data (X_test)",
    "trans.snippet.description.79": "Displaying model output for test data",
    "trans.snippet.description.80": "Predicting for specific input vector",
    "trans.snippet.description.81": "Importing accuracy_score library",
    "trans.snippet.description.82": "Evaluating model accuracy",
    "trans.snippet.description.83": "Importing precision_recall_fscore_support",
    "trans.snippet.description.84": "Calculating precision, recall, f1-score and support",
    "trans.snippet.description.85": "Printing precision, recall, f1-score and support",
    "trans.snippet.description.86": "Loading dataset",
    "trans.snippet.description.87": "Separating input features (X) from target variable (y)",
    "trans.snippet.description.88": "Creating decision tree model",
    "trans.snippet.description.89": "Training decision tree",
    "trans.snippet.description.90": "Predicting values on test data",
    "trans.snippet.description.91": "Creating DataFrame for result comparison",
    "trans.snippet.description.92": "Separating input features (X) from target variable (y)",
    "trans.snippet.description.93": "Calculating residual squares",
    "trans.snippet.description.94": "Summing residual squares",
    "trans.snippet.description.95": "Visualizing actual vs predicted values",
    "trans.snippet.description.96": "Selecting Temperature and Revenue attributes",
    "trans.snippet.description.97": "Creating grid for smoother visualization",
    "trans.snippet.description.98": "Visualizing decision tree",
    "trans.snippet.description.99": "Creating input vector for visualization",
    "trans.snippet.description.100": "Visualizing decision tree",
    "trans.snippet.description.101": "Importing RandomForestClassifier",
    "trans.snippet.description.102": "Creating random forest model",
    "trans.snippet.description.103": "Training random forest model",
    "trans.snippet.description.104": "Predicting values on test data",
    "trans.snippet.description.105": "Getting model parameters",
    "trans.snippet.description.106": "Creating random forest model with 1000 trees",
    "trans.snippet.description.107": "Training random forest model",
    "trans.snippet.description.108": "Predicting probabilities for test data",
    "trans.snippet.description.109": "Predicting log probabilities",
    "trans.snippet.description.110": "Getting feature names",
    "trans.snippet.description.111": "Calculating correlation matrix",
    "trans.snippet.description.112": "Visualizing correlation matrix",
    "trans.snippet.description.113": "Loading dataset",
    "trans.snippet.description.114": "Counting frequency of 'AHD' attribute values",
    "trans.snippet.description.115": "Removing 'Unnamed: 0' column",
    "trans.snippet.description.116": "Converting ChestPain category to numerical values",
    "trans.snippet.description.117": "Converting Thal category to numerical values",
    "trans.snippet.description.118": "Converting AHD category to numerical values",
    "trans.snippet.description.119": "Checking for missing values",
    "trans.snippet.description.120": "Separating input features (X) from target variable (y)",
    "trans.snippet.description.121": "Splitting data into train/test sets",
    "trans.snippet.description.122": "Importing StandardScaler",
    "trans.snippet.description.123": "Creating StandardScaler model",
    "trans.snippet.description.124": "Scaling training data",
    "trans.snippet.description.125": "Scaling test data",
    "trans.snippet.description.126": "Displaying scaled training data",
    "trans.snippet.description.127": "Importing LogisticRegression",
    "trans.snippet.description.128": "Creating and training logistic model",
    "trans.snippet.description.129": "Predicting values on training data",
    "trans.snippet.description.130": "Evaluating model accuracy on training data",
    "trans.snippet.description.131": "Evaluating model accuracy on test data",
    "trans.snippet.description.132": "Predicting probabilities for test data",
    "trans.snippet.description.133": "Importing statsmodels.api",
    "trans.snippet.description.134": "Creating logistic regression model",
    "trans.snippet.description.135": "Training logistic regression model",
    "trans.snippet.description.136": "Displaying statistical model results",
    "trans.snippet.description.137": "Visualizing correlation matrix (formatted values)",
    "trans.snippet.description.138": "Visualizing correlation matrix (large format)",
    "trans.snippet.description.139": "Generating logistic regression predictions",
    "trans.snippet.description.140": "Evaluating logistic regression accuracy",
    "trans.snippet.description.141": "Creating confusion matrix",
    "trans.snippet.description.142": "Generating classification report",
    "trans.snippet.description.143": "Displaying classification report",
    "trans.snippet.description.144": "Importing ROC AUC metrics",
    "trans.snippet.description.145": "Importing ROC curve",
    "trans.snippet.description.146": "Visualizing logistic regression ROC curve",
    "trans.snippet.description.147": "Loading data from GitHub repository",
    "trans.snippet.description.148": "Selecting variables for binary classification",
    "trans.snippet.description.149": "Splitting data into train/test sets",
    "trans.snippet.description.150": "Initializing logistic regression model",
    "trans.snippet.description.151": "Training logistic regression model",
    "trans.snippet.description.152": "Predicting with logistic regression",
    "trans.snippet.description.153": "Initializing Random Forest classifier",
    "trans.snippet.description.154": "Training Random Forest model",
    "trans.snippet.description.155": "Predicting with Random Forest model",
    "trans.snippet.description.156": "Comparing ROC curves of logistic regression and Random Forest",
    "trans.snippet.description.157": "Defining activation function for perceptron (step 0: biological neuron inspiration)",
    "trans.snippet.description.158": "Calculating neuron output (weighted sum of inputs + bias)",
    "trans.snippet.description.159": "Importing numpy library for array operations",
    "trans.snippet.description.160": "Defining training data (input examples and expected outputs)",
    "trans.snippet.description.161": "Initializing weights and bias with random values",
    "trans.snippet.description.162": "Training perceptron using delta rule (weight updates based on error)",
    "trans.snippet.description.163": "Defining decision boundary line for visualization",
    "trans.snippet.description.164": "Importing colors for visualization",
    "trans.snippet.description.165": "Setting inline mode for Jupyter plot display",
    "trans.snippet.description.166": "Visualizing training data and decision boundary",
    "trans.snippet.description.167": "Predicting output for custom input vector",
    "trans.snippet.description.168": "Alternative training set for XOR problem",
    "trans.snippet.description.169": "Importing library for random value generation",
    "trans.snippet.description.170": "Initializing weights and bias with random values (XOR problem)",
    "trans.snippet.description.171": "Training perceptron in epochs (iterating through training data)",
    "trans.snippet.description.172": "Visualizing decision boundary for XOR problem",
    "trans.snippet.description.173": "Importing library for synthetic data generation",
    "trans.snippet.description.174": "Importing tools for cluster data creation",
    "trans.snippet.description.175": "Generating linearly separable data with two classes",
    "trans.snippet.description.176": "Analyzing class distribution in data",
    "trans.snippet.description.177": "Extracting examples belonging to class 1",
    "trans.snippet.description.178": "Visualizing synthetic data with scatter plot",
    "trans.snippet.description.179": "Generating multidimensional data with four clusters",
    "trans.snippet.description.180": "Setting figure size for complex visualizations",
    "trans.snippet.description.181": "Printing data matrix shape",
    "trans.snippet.description.182": "Initializing perceptron weights (zero values)",
    "trans.snippet.description.183": "Implementing perceptron algorithm with visualization",
    "trans.snippet.description.184": "Helper function for decision boundary visualization",
    "trans.snippet.description.185": "Running perceptron algorithm on synthetic data",
    "trans.snippet.description.186": "Defining sum of squared errors function",
    "trans.snippet.description.187": "Test data for model error calculation",
    "trans.snippet.description.188": "Calculating errors between expected and predicted values",
    "trans.snippet.description.189": "Calculating weighted sum of inputs (neuron's internal potential)",
    "trans.snippet.description.190": "Defining linear activation function for Adaline (identity function)",
    "trans.snippet.description.191": "Getting input data matrix shape",
    "trans.snippet.description.192": "Creating bias column for data matrix",
    "trans.snippet.description.193": "Expanding data matrix with bias column",
    "trans.snippet.description.194": "Displaying first 4 rows of expanded matrix",
    "trans.snippet.description.195": "Initializing random number generator with fixed seed",
    "trans.snippet.description.196": "Generating initial weights from normal distribution",
    "trans.snippet.description.197": "Initializing list for storing errors and calculating predictions",
    "trans.snippet.description.198": "Displaying first 4 predicted values",
    "trans.snippet.description.199": "Calculating errors between actual and predicted values",
    "trans.snippet.description.200": "Displaying first 4 model errors",
    "trans.snippet.description.201": "Updating weights using gradient descent",
    "trans.snippet.description.202": "Displaying updated model weights",
    "trans.snippet.description.203": "Calculating loss using sum of squared errors",
    "trans.snippet.description.204": "Training Adaline model for 20 epochs",
    "trans.snippet.description.205": "Implementing Adaline algorithm with automatic data scaling",
    "trans.snippet.description.206": "Creating and training Adaline classifier",
    "trans.snippet.description.207": "Visualizing loss vs epochs relationship",
    "trans.snippet.description.208": "Predicting output for custom input vector",
    "trans.snippet.description.209": "Displaying final trained model weights",
    "trans.snippet.description.210": "Defining input data for XOR problem (2D matrix)",
    "trans.snippet.description.211": "Defining target values for XOR problem",
    "trans.snippet.description.212": "Initializing neural network parameters (2-2-1 architecture)",
    "trans.snippet.description.213": "Defining sigmoid activation function",
    "trans.snippet.description.214": "Implementing forward propagation for two-layer network",
    "trans.snippet.description.215": "Implementing backpropagation for gradient calculation",
    "trans.snippet.description.216": "Training neural network for 100,000 iterations",
    "trans.snippet.description.217": "Visualizing training loss",
    "trans.snippet.description.218": "Function for predicting outputs using trained weights",
    "trans.snippet.description.219": "Testing network on all XOR input combinations",
    "trans.snippet.description.220": "Importing Keras Dense layer for model building",
    "trans.snippet.description.221": "Importing Keras Sequential API",
    "trans.snippet.description.222": "Defining sequential model with three layers",
    "trans.snippet.description.223": "Printing model structure",
    "trans.snippet.description.224": "Compiling model with Adam optimizer and MSE loss",
    "trans.snippet.description.225": "Training model for 50 epochs",
    "trans.snippet.description.226": "Displaying first 6 predictions",
    "trans.snippet.description.227": "Displaying first 6 actual values",
    "trans.snippet.description.228": "Generating predictions for test data",
    "trans.snippet.description.229": "Loading javelin throw dataset",
    "trans.snippet.description.230": "Visualizing pairwise variable relationships",
    "trans.snippet.description.231": "Selecting data for two specific competitors",
    "trans.snippet.description.232": "Analyzing class distribution in data",
    "trans.snippet.description.233": "Encoding text classes to numerical values",
    "trans.snippet.description.234": "Separating input features from target variable",
    "trans.snippet.description.235": "Splitting data into train/test sets",
    "trans.snippet.description.236": "Defining model with single hidden layer",
    "trans.snippet.description.237": "Training model for 200 epochs",
    "trans.snippet.description.238": "Extending class encoding for multi-class classification",
    "trans.snippet.description.239": "Importing one-hot encoding tools",
    "trans.snippet.description.240": "Preparing data for 4-class classification",
    "trans.snippet.description.241": "Defining model for multi-class classification",
    "trans.snippet.description.242": "Compiling model with binary cross-entropy",
    "trans.snippet.description.243": "Converting predictions to class labels",
    "trans.snippet.description.244": "Creating confusion matrix for evaluation",
    "trans.snippet.description.245": "Printing classifier accuracy",
    "trans.snippet.description.246": "Loading and displaying traffic sign image",
    "trans.snippet.description.247": "Getting image data dimensions",
    "trans.snippet.description.248": "Cropping and visualizing image section",
    "trans.snippet.description.249": "Converting color image to grayscale",
    "trans.snippet.description.250": "Zooming and visualizing small image section",
    "trans.snippet.description.251": "Printing pixel values of image section",
    "trans.snippet.description.252": "Visualizing grayscale image",
    "trans.snippet.description.253": "Loading Fashion MNIST dataset",
    "trans.snippet.description.254": "Splitting data into train/test sets",
    "trans.snippet.description.255": "Importing one-hot encoding tools",
    "trans.snippet.description.256": "Analyzing training/test data shape",
    "trans.snippet.description.257": "Identifying unique classes in data",
    "trans.snippet.description.258": "Visualizing example images from dataset",
    "trans.snippet.description.259": "Reshaping images for convolutional networks",
    "trans.snippet.description.260": "Normalizing pixel values to [0,1] range",
    "trans.snippet.description.261": "One-hot encoding target variables",
    "trans.snippet.description.262": "Splitting training data into train/validation",
    "trans.snippet.description.263": "Verifying shapes of all data parts",
    "trans.snippet.description.264": "Importing required Keras API components (Sequential, Model)",
    "trans.snippet.description.265": "Importing required Keras API components (Dense, Dropout, Flatten)",
    "trans.snippet.description.266": "Importing required Keras API components (Conv2D, MaxPooling2D)",
    "trans.snippet.description.267": "Importing required Keras API components (LeakyReLU)",
    "trans.snippet.description.268": "Defining training parameters (batch size, epochs, class count)",
    "trans.snippet.description.269": "CNN architecture with 3 convolutional layers and max pooling",
    "trans.snippet.description.270": "Compiling model with cross-entropy loss and Adam optimizer",
    "trans.snippet.description.271": "Printing model structure with layer/parameter details",
    "trans.snippet.description.272": "Training model on image data with validation",
    "trans.snippet.description.273": "Evaluating model on test set",
    "trans.snippet.description.274": "Visualizing training accuracy and loss",
    "trans.snippet.description.275": "Saving trained model to HDF5 file",
    "trans.snippet.description.276": "Opening text file for reading",
    "trans.snippet.description.277": "Loading text file content",
    "trans.snippet.description.278": "Displaying loaded text content",
    "trans.snippet.description.279": "Cleaning text (removing special characters/punctuation)",
    "trans.snippet.description.280": "Calculating total character count",
    "trans.snippet.description.281": "Calculating number of unique words",
    "trans.snippet.description.282": "Tokenizing text into words",
    "trans.snippet.description.283": "Finding longest word in text",
    "trans.snippet.description.284": "Loading tweets from CSV file",
    "trans.snippet.description.285": "Displaying tweet dataset structure",
    "trans.snippet.description.286": "Defining lambda function for simple addition",
    "trans.snippet.description.287": "Function for counting words in tweets",
    "trans.snippet.description.288": "Applying word count function to entire dataset",
    "trans.snippet.description.289": "Calculating tweet character counts",
    "trans.snippet.description.290": "Calculating average word length in tweets",
    "trans.snippet.description.291": "Importing regex for text processing",
    "trans.snippet.description.292": "Sample tweet for regex demonstration",
    "trans.snippet.description.293": "Basic regex match test",
    "trans.snippet.description.294": "Detecting hashtags with regex",
    "trans.snippet.description.295": "Extracting all hashtags from tweet",
    "trans.snippet.description.296": "Demonstrating regex findall for 'b.+ing' pattern",
    "trans.snippet.description.297": "Validating emails with regex",
    "trans.snippet.description.298": "Importing NLP toolkit (NLTK)",
    "trans.snippet.description.299": "Downloading WordNet lexical database",
    "trans.snippet.description.300": "Importing WordNet corpus",
    "trans.snippet.description.301": "Getting synsets for 'joy'",
    "trans.snippet.description.302": "Extracting lemma names for first synset",
    "trans.snippet.description.303": "Extracting all lemma names",
    "trans.snippet.description.304": "Getting definition for first synset",
    "trans.snippet.description.305": "Finding synonyms/antonyms for given word",
    "trans.snippet.description.306": "Calculating Wu-Palmer similarity between concepts",
    "trans.snippet.description.307": "Demonstrating low semantic similarity",
    "trans.snippet.description.308": "Importing HTTP request library",
    "trans.snippet.description.309": "Loading webpage using GET request",
    "trans.snippet.description.310": "Importing HTML parser from lxml",
    "trans.snippet.description.311": "Creating HTML tree from page content",
    "trans.snippet.description.312": "Extracting headings using XPath",
    "trans.snippet.description.313": "Loading eBay product data",
    "trans.snippet.description.314": "Complex product price extraction/analysis",
    "trans.snippet.description.315": "Alternative eBay price extraction method",
    "trans.snippet.description.316": "Normalizing price formats",
    "trans.snippet.description.317": "Extracting emails from university website",
    "trans.snippet.description.318": "Validating emails with regex",
    "trans.snippet.description.319": "Downloading NLTK tokenizer module",
    "trans.snippet.description.320": "Sample text for NLP operations",
    "trans.snippet.description.321": "Importing word tokenizer",
    "trans.snippet.description.322": "Tokenizing text into words",
    "trans.snippet.description.323": "Normalizing text to lowercase",
    "trans.snippet.description.324": "Tokenizing normalized text",
    "trans.snippet.description.325": "Creating word frequency distribution",
    "trans.snippet.description.326": "Getting top 5 frequent words",
    "trans.snippet.description.327": "Loading esoteric texts website using requests.get()",
    "trans.snippet.description.328": "Extracting headings using XPath (//body/a/text())",
    "trans.snippet.description.329": "Aggregating all headings into single string",
    "trans.snippet.description.330": "Tokenizing aggregated text into words",
    "trans.snippet.description.331": "Normalizing tokens to lowercase",
    "trans.snippet.description.332": "Importing FreqDist for frequency analysis",
    "trans.snippet.description.333": "Creating word frequency distribution",
    "trans.snippet.description.334": "Getting top 10 frequent words",
    "trans.snippet.description.335": "Extracting all hyperlinks using XPath",
    "trans.snippet.description.336": "Complex scraping with recursive subpage loading",
    "trans.snippet.description.337": "Loading book text from Project Gutenberg",
    "trans.snippet.description.338": "Setting UTF-8 encoding for text interpretation",
    "trans.snippet.description.339": "Extracting clean text from HTTP response",
    "trans.snippet.description.340": "Showing first 200 characters of raw HTML",
    "trans.snippet.description.341": "Importing BeautifulSoup for advanced HTML parsing",
    "trans.snippet.description.342": "Creating BeautifulSoup object for DOM traversal",
    "trans.snippet.description.343": "Extracting clean text without HTML tags",
    "trans.snippet.description.344": "Initializing regex tokenizer for words",
    "trans.snippet.description.345": "Tokenizing text with custom regex pattern",
    "trans.snippet.description.346": "Normalizing tokens to lowercase",
    "trans.snippet.description.347": "Calculating normalized word frequency distribution",
    "trans.snippet.description.348": "Downloading NLTK English stopwords",
    "trans.snippet.description.349": "Importing stopwords corpus",
    "trans.snippet.description.350": "Loading English stopwords into variable",
    "trans.snippet.description.351": "Filtering stopwords from tokenized text",
    "trans.snippet.description.352": "Creating clean word frequency distribution",
    "trans.snippet.description.353": "Visualizing top 20 frequent words using FreqDist.plot()",
    "trans.code.name.1": "Decision Tree Training and Visualization",
    "trans.code.name.2": "Diabetes Classification with Decision Tree",
    "trans.code.name.3": "Titanic Survival Prediction with Tree Classifiers",
    "trans.code.name.4": "Titanic Decision Tree Inference and Custom Prediction",
    "trans.code.name.5": "Age Regression with Decision Tree on Possum Dataset",
    "trans.code.name.6": "Evaluation of Diabetes Classification with Decision Tree",
    "trans.code.name.7": "Ice Cream Revenue Prediction Using Decision Tree Regression",
    "trans.code.name.8": "Tree-Based Regression and Classification on Ice Cream and Titanic Data",
    "trans.code.name.9": "Titanic Survival Prediction Using Random Forest Classifier",
    "trans.code.name.10": "Heart Disease Prediction Using Logistic Regression",
    "trans.code.name.11": "Heart Disease Risk Prediction: Logistic Regression vs. Random Forest",
    "trans.code.name.12": "Single Neuron Training and Linearly Separable Data",
    "trans.code.name.13": "Perceptron Algorithm with Visualized Training",
    "trans.code.name.14": "Adaline Learning and Error Minimization",
    "trans.code.name.15": "Basic Neural Network Training for XOR Function",
    "trans.code.name.16": "Titanic Survival Prediction Using a Neural Network",
    "trans.code.name.17": "Darts Data Classification with Decision Tree and Neural Network",
    "trans.code.name.18": "Multiclass Classification of Darts Players Using Neural Networks",
    "trans.code.name.19": "Fashion MNIST Image Classification with CNN",
    "trans.code.name.20": "Text Processing and Tweet Analysis with Regex",
    "trans.code.name.21": "WordNet-Based Synonym and Antonym Extraction with Web Scraping",
    "trans.code.name.22": "Email Extraction and Word Frequency Analysis with NLTK",
    "trans.code.name.23": "Large-Scale Web Text Mining and Stopword Filtering"
}
